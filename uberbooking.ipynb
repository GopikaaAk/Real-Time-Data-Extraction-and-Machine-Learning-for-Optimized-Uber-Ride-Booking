# Import Libraries
import pandas as pd
import numpy as np
import pickle
import requests
from bs4 import BeautifulSoup
import mysql.connector
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
#Database Configuration
# -------------------------------
DB_CONFIG = {
    "host": "localhost",
    "user": "your_user",
    "password": "your_password",
    "database": "uber_db"
}
#Function to Connect to MySQL (Previously database.py)
# -------------------------------
def connect_to_db():
    return mysql.connector.connect(**DB_CONFIG)
# Store scraped data into MySQL
def store_data(data):
    connection = connect_to_db()
    cursor = connection.cursor()
    query = "INSERT INTO ride_fares (fare, wait_time) VALUES (%s, %s)"
    cursor.execute(query, (data["fare"], data["wait_time"]))
    connection.commit()
    connection.close()
# Fetch the latest stored fare data
def fetch_latest_data():
    connection = connect_to_db()
    cursor = connection.cursor(dictionary=True)
    cursor.execute("SELECT * FROM ride_fares ORDER BY id DESC LIMIT 1")
    result = cursor.fetchone()
    connection.close()
    return result
#Uber Data Scraping (Previously data_scraper.py)
# -------------------------------
def extract_uber_data():
    url = "https://www.uber.com/ride-fares/"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Modify based on actual Uber website structure
    fare = soup.find("span", class_="fare-price").text
    wait_time = soup.find("span", class_="wait-time").text

    data = {
        "fare": float(fare.replace("$", "")),
        "wait_time": int(wait_time.replace(" mins", ""))
    }
    return data
# Run the scraper and store data in MySQL
ride_data = extract_uber_data()
store_data(ride_data)
print("✅ Data extracted and stored successfully!")
#Machine Learning Model Training
# -------------------------------

# Load dataset from MySQL (Instead of a CSV file)
def load_data():
    connection = connect_to_db()
    cursor = connection.cursor(dictionary=True)
    cursor.execute("SELECT * FROM ride_fares")
    result = cursor.fetchall()
    connection.close()
    return pd.DataFrame(result)
# Load Uber ride fare dataset
data = load_data()

# Feature Engineering: Convert Time to Numeric
data["time_numeric"] = pd.to_datetime(data["created_at"]).dt.hour

# Define Features (X) and Target Variable (y)
X = data[["time_numeric"]]
y = data["fare"]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Regression Model
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluate Model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Model Mean Squared Error (MSE): {mse:.2f}")
#Save Trained Model
# -------------------------------
with open("fare_prediction_model.pkl", "wb") as file:
    pickle.dump(model, file)

print("✅ Machine Learning Model Saved Successfully!")




